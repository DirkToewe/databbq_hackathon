{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenPetition.de Recommendation System\n",
    "\n",
    "The following Jupyter notebook was created during the [DataBBQ \"Open Data in Action\"](https://www.meetup.com/de-DE/Data-Visualization-RheinMain/events/239007070/), organized by the [DataVizRM Meetup](https://www.meetup.com/de-DE/Data-Visualization-RheinMain/) and hosted by [SAS](https://www.sas.com/de_de/company-information/office-listing.html) in Heidelberg.\n",
    "\n",
    "This notebook is part of a team effort for the mini-hackathon held during the BBQ. The team members are:\n",
    "  * Cornelius Schwab\n",
    "  * Danny Tobisch\n",
    "  * Dilshod\n",
    "  * Dirk Toewe\n",
    "\n",
    "The goal of the hackathon was to improve the [openpetition](https://www.openpetition.de/) platform using the the anonymized user data which was published beforehand. This notebook represents the preprocessing step used to convert the user into a reduced form suited for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% matplotlib notebook\n",
    "from pandas import read_csv, DataFrame\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, groupby\n",
    "import csv, os, numpy as np, pandas as pd\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Raw Data\n",
    "\n",
    "For our recommendation system we needed to know, for each pair of petitions (p,q), how many signatures they have in common. Our hypothesis was that if two petitions have alot of signatures in common they are closely related and for a new signer of p, q would be a sensible recommendation in that case.\n",
    "\n",
    "The signature data can be found in *signer.csv*. The file is however to large to read in as [DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). Instead the data is streamed using the [csv](https://docs.python.org/2/library/csv.html) module. Unnecessary data is discarded directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def signatures():\n",
    "\n",
    "  filepath = os.path.expanduser('~/Documents/openpetition_data/signer.csv')\n",
    "\n",
    "  with open(filepath,'r') as file:\n",
    "\n",
    "    def lines():\n",
    "      prgrs= FloatProgress(\n",
    "        description = '0%',\n",
    "        min=0, max=os.path.getsize(filepath)\n",
    "      )\n",
    "      prgrs_val = 0\n",
    "      display(prgrs)\n",
    "      for line in file:\n",
    "        yield line\n",
    "        prgrs_val += len( line.encode('utf-8') )\n",
    "        if prgrs_val*100//prgrs.max != prgrs.value*100//prgrs.max:\n",
    "          prgrs.description = '%3d%%' % (prgrs_val*100//prgrs.max)\n",
    "          prgrs.value = prgrs_val\n",
    "\n",
    "    reader = csv.reader(lines(), delimiter=',', quotechar='\"')\n",
    "\n",
    "    head = { field: i for i,field in enumerate(next(reader)) }\n",
    "    iEmail= head['email']\n",
    "    iPid  = head['petition_id']\n",
    "    del head\n",
    "    emails = []\n",
    "\n",
    "    def pids():\n",
    "        \n",
    "      for row in reader:\n",
    "        email = row[iEmail]\n",
    "        if 0 < len(email):\n",
    "          pid = row[iPid]\n",
    "          assert pid.startswith('=')\n",
    "          emails.append(email)\n",
    "          yield pid[1:]\n",
    "\n",
    "    pids = np.fromiter( pids(), dtype= np.int64 )\n",
    "    return emails,pids\n",
    "\n",
    "signatures = signatures()\n",
    "signatures = DataFrame({\n",
    "  'email'      : signatures[0],\n",
    "  'petition_id': signatures[1]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed results are a list of email-petition_id-pairs, each of which represents a person signing for particular petition. We hereby assumed the E-Mail to be a unique identifier for assigner. Anonymous signatures, i.e. without E-Mail were discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by E-Mail\n",
    "\n",
    "The data presentation is not ideal for the purposes of a recommendation system yet. We are not interested in particular signatures but rather in all signatures that two petitions have in common. The first step of processing to group all petition_ids signed by an individual e-mail/user. At the same time we can already filter out all the e-mail only used to sign a single petition as they don't give us any connection between two or more petitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multisigner = defaultdict(set)\n",
    "for row in signatures.itertuples():\n",
    "  multisigner[row.email].add(row.petition_id)\n",
    "\n",
    "del signatures # <- save memory\n",
    "\n",
    "multisigner = {\n",
    "  k : np.fromiter(v, dtype=np.int64)\n",
    "  for k,v in multisigner.items()\n",
    "  if len(v) > 1\n",
    "}\n",
    "multisigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Outliers\n",
    "\n",
    "It is interesting to see what is the highest number of petitions signed using the same e-mail. As is turns out there is an e-mail which was used in 2174 petitions which is more than suspicious. Overall there are however only 88 e-mails used in more than 200 petitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bot = max( multisigner.items(), key = lambda kv: len(kv[1]) )\n",
    "print( len(bot[1]) )\n",
    "len({\n",
    "  k : v\n",
    "  for k,v in multisigner.items()\n",
    "  if len(v) > 200\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us filter out all the users which have signed a hundred petitions of less considering them as \"normal\" users. As it turns out the remaining sample size is still over 1 million, which is more than reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nonbots = {\n",
    "  k: v\n",
    "  for k,v in multisigner.items()\n",
    "  if len(v) <= 100\n",
    "}\n",
    "len(nonbots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Graph\n",
    "\n",
    "In this final step data transformation, we turn the data into a weighted <a href=\"https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)\">undirected graph</a>. For each pair of petitions a user has signed, we count up the weight of the edge between the petitions by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = Counter(\n",
    "  ab\n",
    "  for v in nonbots.values()\n",
    "  for ab in permutations(v,2)\n",
    ")\n",
    "\n",
    "print( len(graph) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to is to save the data so that we can visualize it. We utilized [Microsoft Power BI](https://powerbi.microsoft.com/de-de/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open( os.path.expanduser('~/Documents/openpetition_data/graph.csv'), 'w') as signer:\n",
    "  writer = csv.writer(signer, delimiter=',', quotechar='\"')\n",
    "  writer.writerow(['petition_from','petition_to','weight'])\n",
    "  for (a,b),n in graph.items():\n",
    "    writer.writerow([a,b,n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing to Recommendations\n",
    "\n",
    "Since the graph potentially contains a large amount of edges, we can go on an remove all but the 5 strongest edges for each petition node. Keep in mind that this results in a *directed graph*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommendations = defaultdict(list)\n",
    "\n",
    "for (a,b),n in graph.items():\n",
    "  recommendations[a] += [b,n]\n",
    "\n",
    "nVertices = 5\n",
    "\n",
    "def rows():\n",
    "  for a,bn in recommendations.items():\n",
    "    bn = np.array(bn).reshape(-1,2)\n",
    "    yield a, bn[ np.lexsort(bn.T)[:-nVertices-1:-1] ]\n",
    "\n",
    "recommendations = list( rows() )\n",
    "\n",
    "del rows\n",
    "recommendations.sort(key = lambda kv: kv[0])\n",
    "for k,v in recommendations[:+2]:\n",
    "  print('%d ->\\n%s' % (k,v) )\n",
    "print('...')\n",
    "for k,v in recommendations[-2:]:\n",
    "  print('%d ->\\n%s' % (k,v) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also incorporate the petition name into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "petitions = read_csv(\n",
    "  os.path.expanduser('~/Documents/openpetition_data/petition.csv'),\n",
    "  index_col='petition_id', usecols=['petition_id','title']\n",
    ")\n",
    "assert petitions.index.str.startswith('=').all()\n",
    "petitions.index = pd.to_numeric( petitions.index.str[1:] )\n",
    "petitions = petitions.loc[np.fromiter( (a for (a,_) in graph), dtype=np.int64 )]\n",
    "\n",
    "petitions = {\n",
    "  row[0]: row.title\n",
    "  for row in petitions.itertuples()\n",
    "}\n",
    "petitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open( os.path.expanduser('~/Documents/openpetition_data/recommendations.csv'), 'w') as signer:\n",
    "  writer = csv.writer(signer, delimiter=',', quotechar='\"')\n",
    "  writer.writerow(['petition_from','petition_to','weight','title_from','title_to'])\n",
    "  for a,bn in recommendations:\n",
    "    for b,n in bn:\n",
    "      writer.writerow([\n",
    "        a,b,n,\n",
    "        petitions[a],\n",
    "        petitions[b]\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mech_eng]",
   "language": "python",
   "name": "conda-env-mech_eng-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "e10013c1e1f945a383b5db45ca9dcbe0": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
